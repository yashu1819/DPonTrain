{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"../Data/irctc/schedules.json\"        # Your original file with errors\n",
    "output_file = \"../Data/irctc/schedules_array.json\"   # New file to contain valid JSON objects\n",
    "error_log_file = \"error_log.txt\"       # File to log errors\n",
    "\n",
    "valid_objects = []\n",
    "error_lines = []\n",
    "\n",
    "# Open the input file and process each line\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile:\n",
    "    for line_number, line in enumerate(infile, start=1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # skip blank lines\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            valid_objects.append(obj)\n",
    "        except json.JSONDecodeError as e:\n",
    "            error_message = f\"Line {line_number}: {e}\"\n",
    "            error_lines.append(error_message)\n",
    "            # Optionally print the error message\n",
    "            # print(error_message)\n",
    "\n",
    "# Write valid objects into a JSON array\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(valid_objects, outfile, indent=2)\n",
    "\n",
    "# Optionally, write errors to a log file for further review\n",
    "if error_lines:\n",
    "    with open(error_log_file, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        for error in error_lines:\n",
    "            log_file.write(error + \"\\n\")\n",
    "\n",
    "# print(f\"Processing complete. {len(valid_objects)} valid objects written to {output_file}.\")\n",
    "# if error_lines:\n",
    "#     print(f\"{len(error_lines)} errors logged to {error_log_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stationCode\n",
      "NDLS    1199.0\n",
      "CNB     1132.0\n",
      "BZA     1012.0\n",
      "HWH      964.0\n",
      "ET       960.0\n",
      "KYN      933.0\n",
      "ST       929.0\n",
      "BRC      887.0\n",
      "BSL      860.0\n",
      "UMB      843.0\n",
      "Name: runsPerWeek, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the JSON array from your file.\n",
    "with open('../Data/irctc/schedules.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Flatten the JSON: each row will be a stop from a train schedule.\n",
    "df = pd.json_normalize(\n",
    "    data,\n",
    "    record_path=['stationList'],\n",
    "    meta=['trainNumber',\n",
    "          'trainRunsOnMon', 'trainRunsOnTue', 'trainRunsOnWed',\n",
    "          'trainRunsOnThu', 'trainRunsOnFri', 'trainRunsOnSat',\n",
    "          'trainRunsOnSun']\n",
    ")\n",
    "\n",
    "# 3. Convert run-day flags (which are \"Y\" or \"N\") to numeric values.\n",
    "run_flags = ['trainRunsOnMon', 'trainRunsOnTue', 'trainRunsOnWed',\n",
    "             'trainRunsOnThu', 'trainRunsOnFri', 'trainRunsOnSat', 'trainRunsOnSun']\n",
    "\n",
    "for flag in run_flags:\n",
    "    df[flag] = df[flag].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# 4. Calculate runs per week for each schedule (each row gets the same weekly value).\n",
    "df['runsPerWeek'] = df[run_flags].sum(axis=1)\n",
    "\n",
    "# 5. Group by station code and sum up the weekly stops.\n",
    "busiest_stations = df.groupby('stationCode')['runsPerWeek'].sum().sort_values(ascending=False)\n",
    "\n",
    "# 6. Display the top 10 busiest station codes.\n",
    "print(busiest_stations.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already computed busiest_stations as follows:\n",
    "# busiest_stations = df.groupby('stationCode')['runsPerWeek'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Save the Series to a CSV file\n",
    "busiest_stations.to_csv(\"../Data/precomputes/weekly_traffic_stations.csv\", header=[\"weeklyStops\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
